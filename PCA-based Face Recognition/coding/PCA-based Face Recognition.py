# -*- coding: utf-8 -*-
"""Lab3_spate235.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VxoLVHOg6VE0sR_ArKu8mXVXcsGaUfWj

# Lab 3 PCA-based Face Recognition

For all of the following, program the solution yourself. Don't just call a library function that does the whole question for you, or you'll get zero (no, that doesn't mean you can't use any library functions, but it does mean that you have to show you understand how to compute the answer yourself).

**Copy your Colab link here:**

Import package here
"""

import numpy as np
import matplotlib.pyplot as plt

"""**Step 0. Moving the lab to your folder as well as copy and paste a shared link here**

Duplicate this notebook (as you won't have write permission to this) to your Google Drive.
This can be done by clicking on *File Menu - Save a copy in Drive*

**Shared link:**https://colab.research.google.com/drive/1VxoLVHOg6VE0sR_ArKu8mXVXcsGaUfWj?usp=sharing

Run to mount your google drives:
"""

from google.colab import drive
drive.mount('/content/drive')

"""Your drive would be accessed as '/content/drive/MyDrive' for Colab. You may need to put your data and creating a 'results' folder somewhere in the drive. The 'results' folder could be used for storing the required outputs.   """

# example goes like:
DataPath  = '/content/drive/MyDrive/Dataset/Dataset'
ResultPath = '/content/drive/MyDrive/Dataset/Dataset/Result'

"""**Step 1: Load the training data**

Read all the training images, reshape them into a vector and store them into the columns of a 10304x360 matrix where 360 is the total number of images and 10304 (=112*92) is the dimension of the vectors.

"""

# import os
# from PIL import Image
# from sklearn.metrics import accuracy_score
# from PIL import Image

# DataPath = '/content/drive/MyDrive/Dataset/Dataset/orlfaces/Train/'

# image_matrix = np.zeros((10304, 360))

# image_index = 0
# for person in range(1, 41):
#     folder_path = os.path.join(DataPath, f's{person}')

#     # Load 9 images for training from each person's folder
#     for img_num in range(1, 10):
#         img_path = os.path.join(folder_path, f'{img_num}.pgm')
#         img = Image.open(img_path)
#         # .convert('L')
#         img_vector = np.asarray(img).reshape(10304)
#         image_matrix[:, image_index] = img_vector
#         image_index += 1
import os
import numpy as np
from PIL import Image

DataPath = '/content/drive/MyDrive/Dataset/Dataset/orlfaces/Train/'

image_matrix = np.zeros((10304, 360))  # Assuming 360 images
labels = []  # List to store labels

image_index = 0
for person in range(1, 41):
    folder_path = os.path.join(DataPath, f's{person}')

    # Load 9 images for training from each person's folder
    for img_num in range(1, 10):
        img_path = os.path.join(folder_path, f'{img_num}.pgm')
        img = Image.open(img_path)

        img_vector = np.asarray(img).reshape(10304)  # Flatten the image
        image_matrix[:, image_index] = img_vector
        labels.append(f's{person}')  # Append label for the current image
        image_index += 1

# Convert labels to a NumPy array for easier handling if needed
y_train = np.array(labels)

# Now image_matrix contains image data and labels_array contains corresponding labels

"""**Step 2: Perform PCA to extract the eigen-faces**

1. Center the data
2. Compute the correlation matrix
3. Use either the SVD or eig function from numpy.linalg to perform SVD/eigen-decomposition and get the eigenvectors and eigenvalues of the correlation matrix.
4. Normalize the eigenvectors by their L2 norm if necessary.


"""

mean_face = np.mean(image_matrix, axis=1).reshape(-1, 1)   # Center the data
centered_matrix = image_matrix - mean_face

correlation_matrix = np.dot(centered_matrix.T, centered_matrix)

U, S, Vt = np.linalg.svd(centered_matrix, full_matrices=False) # Performing SVD
eigenfaces = np.dot(centered_matrix, Vt.T)
eigenfaces_normalized = eigenfaces / np.linalg.norm(eigenfaces, axis=0)

"""**Step 3: Plot the eigenvalues**

Sort the eigenvectors and eigenvalues in descending order. Then plot the eigenvalues.


"""

eigenvalues = S**2
eigenvalues_sorted = np.sort(eigenvalues)[::-1]

# Plot the sorted eigenvalues
plt.figure(figsize=(8, 6))
plt.plot(eigenvalues_sorted, marker='o', linestyle='-', color='b')
plt.title('Sorted Eigenvalues')
plt.xlabel('Index')
plt.ylabel('Eigenvalue')
plt.grid(True)
plt.show()

data_matrix = data_matrix.T

"""**Step 4: Plot the first 3 eigenfaces and the last eigenface**

Remember that the images were mean-normalized and reshaped into vectors. So to plot the eigenvalues, you have to undo these steps.
"""

fig, axes = plt.subplots(1, 4, figsize=(15, 8))

for i, idx in enumerate([0, 1, 2, -1]):
    eigenface = eigenfaces_normalized[:, idx].reshape(112, 92)
    axes[i].imshow(eigenface, cmap='gray')
    axes[i].set_title(f"Eigenface {idx+1}" if idx != -1 else "Final Eigenface")


plt.show()

"""**Step 5: Pick a face and reconstruct it using $k = {10, 20, 30, 40, 100, 200, 300}$ eigenvectors.**

Plot all of these reconstructions and compare them. For each value of $k$, plot the original image, reconstructed image, and the difference between the original image and reconstruction in each case. Write your observations.
"""

face_index = 0  # Index of the face to reconstruct
original_face = centered_matrix[:, face_index]

# Function to reconstruct a face using the top k eigenfaces
def reconstruct_face_with_eigenfaces(k, eigenfaces, face):
    projection = np.dot(eigenfaces[:, :k].T, face)
    reconstructed_face = np.dot(eigenfaces[:, :k], projection)
    return reconstructed_face

k_values = [10, 20, 30, 40, 100, 200, 300]  # Different values of k for reconstruction

# Set up the figure for displaying results
fig, axes = plt.subplots(len(k_values), 3, figsize=(12, 20))

for idx, k in enumerate(k_values):
    reconstructed_face = reconstruct_face_with_eigenfaces(k, eigenfaces_normalized, original_face)

    # Plot the original face
    axes[idx, 0].imshow(original_face.reshape(112, 92) + mean_face.reshape(112, 92), cmap='gray')
    axes[idx, 0].set_title("Original Face")
    axes[idx, 0].axis('off')

    # Plot the reconstructed face
    axes[idx, 1].imshow(reconstructed_face.reshape(112, 92) + mean_face.reshape(112, 92), cmap='gray')
    axes[idx, 1].set_title(f"Reconstructed (k={k})")
    axes[idx, 1].axis('off')

    # Plot the difference between the original and reconstructed face
    difference = original_face - reconstructed_face
    axes[idx, 2].imshow(difference.reshape(112, 92), cmap='gray')
    axes[idx, 2].set_title(f"Difference (k={k})")
    axes[idx, 2].axis('off')

# Adjust layout to prevent overlap and show the plot
plt.tight_layout()
plt.show()

"""**Step 6: Load the testing data, and reshape it similar to the training data.**


"""

# test_data_path = '/content/drive/MyDrive/Dataset/Dataset/orlfaces/Test/'

# test_image_matrix = np.zeros((10304, 40))

# test_image_index = 0
# for person in range(1, 41):
#     folder_path = os.path.join(test_data_path, f's{person}')

#     test_img_path = os.path.join(folder_path, '10.pgm')
#     img = Image.open(test_img_path)
#     #.convert('L')

#     test_image_matrix[:, test_image_index] = np.asarray(img).reshape(10304)
#     test_image_index += 1

# # Center the testing data
# centered_test_matrix = test_image_matrix - mean_face

import os
import numpy as np
from PIL import Image

test_data_path = '/content/drive/MyDrive/Dataset/Dataset/orlfaces/Test/'

test_image_matrix = np.zeros((10304, 40))  # Assuming 40 test images
test_labels = []  # List to store labels

test_image_index = 0
for person in range(1, 41):
    folder_path = os.path.join(test_data_path, f's{person}')

    test_img_path = os.path.join(folder_path, '10.pgm')
    img = Image.open(test_img_path)

    test_image_matrix[:, test_image_index] = np.asarray(img).reshape(10304)
    test_labels.append(f's{person}')  # Append label for the current test image
    test_image_index += 1

# Convert test labels to a NumPy array for easier handling if needed
y_test = np.array(test_labels)

# Center the testing data
centered_test_matrix = test_image_matrix - mean_face

# Now test_image_matrix contains test image data and test_labels_array contains corresponding labels

"""**Step 7: For each photograph in the testing dataset, predict the identity of the person.**

You will implement a classifier to do this following these steps -

1. Determine the projection of each test photo onto different number of eigenfaces- $d = {10, 20, 30, 40}$
2. Compare the distance of this projection to the projections of all images in the training data .
3. For each test photo's projection, find the closest category of projection in the training data.
4. Calculate and print the accuracy for different $d$

"""

!pip install scikit-learn
import sklearn.datasets

# def classify_using_pca_svd(X_train, X_test, y_train, y_test, d_values):
#     accuracies = {}

#     mean_face = np.mean(X_train, axis=0).reshape(1, -1)

#     # SVD on centered training data
#     centered_train = X_train - mean_face
#     U, S, Vt = np.linalg.svd(centered_train, full_matrices=False)
#     eigenfaces = Vt.T

#     for d in d_values:

#         eigenfaces_d = eigenfaces[:, :d]
#         projections_train = np.dot(centered_train, eigenfaces_d)
#         projections_test = np.dot(X_test - mean_face, eigenfaces_d)
#         y_pred = []
#         for test_proj in projections_test:
#             distances = np.linalg.norm(projections_train - test_proj, axis=1)
#             closest_idx = np.argmin(distances)
#             y_pred.append(y_train[closest_idx])

#         # Calculate the accuracy for this value of 'd'
#         accuracy = accuracy_score(y_test, y_pred) * 100
#         accuracies[d] = accuracy
#         print(f"Accuracy with {d} eigenfaces: {accuracy:.2f}%")

#     return accuracies

# d_values = [10, 20, 30, 40]
# accuracies = classify_using_pca_svd(image_matrix, test_image_matrix, y_train, y_test, d_values)


def classify_using_pca_svd(X_train, X_test, y_train, y_test, d_values):
    accuracies = {}

    # Calculate the mean face from the training data
    mean_face_train = np.mean(X_train, axis=0)
    mean_face_test = np.mean(X_test, axis = 0)

    # Center the training data
    centered_train = X_train - mean_face_train
    centered_test = X_test - mean_face_test

    # SVD on centered training data
    U, S, Vt = np.linalg.svd(centered_train, full_matrices=False)
    eigenfaces = Vt.T

    Ut, St, Vtt = np.linalg.svd(centered_test, full_matrices=False)
    eigenfacest = Vtt.T

    for d in d_values:
        # Select the top 'd' eigenfaces
        eigenfaces_d = eigenfaces[:, :d]
        eigenfacest_d = eigenfacest[:, :d]

        # Project training data onto the eigenfaces
        projections_train = np.dot(centered_train, eigenfaces_d)

        # Center the test data using the mean face
        projections_test = np.dot(centered_test, eigenfacest_d)

        y_pred = []
        for test_proj in projections_test:
            # Compute distances from the test projection to all training projections
            distances = np.linalg.norm(projections_train - test_proj, axis=1)
            closest_idx = np.argmin(distances)  # Find index of closest training image
            y_pred.append(y_train[closest_idx])  # Append the label of the closest image

        # Calculate accuracy for this value of 'd'
        accuracy = accuracy_score(y_test, y_pred) * 100
        accuracies[d] = accuracy
        print(f"Accuracy with {d} eigenfaces: {accuracy:.2f}%")

    return accuracies


# Example d_values
d_values = [10, 20, 30, 40]

# Assuming y_train and y_test are defined with the correct labels
accuracies = classify_using_pca_svd(image_matrix, test_image_matrix, labels_array, test_labels_array, d_values)

"""**Step 8: Show the closest image in the training dataset for the $s_1$ test example.**

"""

# Assuming train_labels is a list of labels corresponding to the training images
# Example: if you have labels for people in your dataset
def show_image(image_vector, title="Image"):
    image = image_vector.reshape (112, 92)
    plt.imshow(image, cmap='gray')
    plt.title(title)
    plt.ticks(())
    plt.yticks(())
    plt.show()


test_image = test_image.flatten()
mean_face = mean_face.flatten()
centered_test_image = test_image - mean_face
centered_test_image = centered_test_image.reshape(-1)
projection_test = np.dot(eigenfaces.T, centered_test_image)
X_train = X_train.reshape(X_train.shape[0], -1)
centered_X_train = X_train - mean_face
projections_train = np.dot(centered_X_train, eigenfaces)
distances = np.linalg.norm(projections_train - projection_test, axis=1)
closest_index = np.argmin(distances)
show_image(test_image, title="Test Image")
show_image(X_train[closest_index], title=f"Closest Training Image (index {closest_index})")

d = 40  # Number of eigenfaces to use
test_index = 0  # Index for s1 (first test image)
show_closest_image(test_data_matrix, train_data_matrix, train_labels, sorted_eigenfaces, mean_face, d, test_index)

"""**Step 9: Apply your PCA algorithm to dataset of images of Pokemon sprites called pokemon.csv.**

Load the dataset from the file ``pokemon.csv`` using ``np.loadtxt``. The datafile represents a 2d array where each row is a 64 by 64 pixel greyscale picture. The entries are floats between 0 and 1, where 0 is white and 1 is black.

Note that while the images are 64 by 64 entries, the dataset you load has rows of size 4096 (which is $64\times 64$) to allow the data to be saved as a 2D array.

---

**(a):** Combine your previous steps into one pca function as required below. Your function should take the data matrix and the number of components you wish to calculate and return two matrices:
1. The projection of the data onto the principal components
2. The actual components (eigenvectors) themselves.


---
"""

def load_data_from_file(filepath):
    """Load dataset from a specified file."""
    return np.loadtxt(filepath, delimiter=' ')

def perform_pca(dataset, num_components):
    """Perform PCA on the dataset."""
    mean_image = np.mean(dataset, axis=0)
    centered_data = dataset - mean_image
    covariance_matrix = np.cov(centered_data.T)
    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)

    # Sort eigenvalues and eigenvectors
    sorted_indices = np.argsort(eigenvalues)[::-1]
    eigenvectors = eigenvectors[:, sorted_indices]
    eigenvalues = eigenvalues[sorted_indices]

    # Retain the top num_components
    eigenvectors = eigenvectors[:, :num_components]
    projections = np.dot(centered_data, eigenvectors)

    return projections, eigenvectors

# Load Pokémon data from CSV file
pokemon_data = load_data_from_file('/content/drive/MyDrive/Dataset/Dataset/orlfaces/pokemon.csv')

num_components = 10
projections, eigenvectors = perform_pca(pokemon_data, num_components)

def display_image(image_vector, title="Image"):
    """Display an image given its vector representation."""
    image = image_vector.reshape(64, 64)
    plt.imshow(image, cmap='gray')
    plt.title(title)
    plt.axis('off')  # Hide axis for better visualization
    plt.show()

def display_eigenvector(eigenvector, index):
    """Display a specific eigenvector as an image."""
    eigenvector = np.real(eigenvector)  # Ensure eigenvector is real
    display_image(eigenvector, title=f'Eigenvector {index + 1}')  # Adjust index for title

# Display the first few eigenvectors
for i in range(num_components):
    display_eigenvector(eigenvectors[:, i], i)

# Display a sample Pokémon image
display_image(pokemon_data[0], "Sample Pokémon Image")

"""## Eigen-pokemon

If we perform PCA on a dataset, we expect the principal components to lie in the neighbourhood of our datapoints. In particular, if we do this on a dataset of images, we can interpret the principal components as images.

The following function plots a gallery of images.
"""

# Visualising images
def plot_gallery(images, titles, h, w, n_row=2, n_col=6):
    """Helper function to plot a gallery of portraits.
    Arguments: images: a matrix where each row is an image.
    titles: an array of labels for each image.
    h: the height in pixels of each image.
    w: the width in pixels of each image.
    n_row: the number of rows of images to print.
    n_col: the number of columns of images to print."""
    assert len(images) >= n_row * n_col
    assert len(titles) >= n_row * n_col
    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape((h, w)), cmap=plt.cm.gray)
        plt.title(titles[i], size=12)
        plt.xticks(())
        plt.yticks(())
    plt.show()

"""---

**(b):** Use ``plot_gallery`` to plot the first 30 pokemon images.

---
"""

def plot_gallery(images, titles, n_row=5, n_col=6, image_shape=(64, 64), title="Gallery"):
    """
    Plots a gallery of images with titles.

    Args:
    - images: List or array of image vectors (each row is a flattened image).
    - titles: List of titles for each image.
    - n_row: Number of rows in the gallery.
    - n_col: Number of columns in the gallery.
    - image_shape: The shape of each image (height, width). Default is (64, 64).
    - title: The title for the gallery.
    """
    assert len(images) >= n_row * n_col
    assert len(titles) >= n_row * n_col
    plt.figure(figsize=(1.8 * n_col, 2.4 * n_row))
    plt.suptitle(title, size=16)
    for i in range(n_row * n_col):
        plt.subplot(n_row, n_col, i + 1)
        plt.imshow(images[i].reshape(image_shape), cmap='gray')
        plt.title(titles[i], size=10)
        plt.xticks(())
        plt.yticks(())
    plt.show()

pokemon_titles = [f"Pokemon {i+1}" for i in range(30)]

plot_gallery(pokemon_data[:30], pokemon_titles, n_row=5, n_col=6, image_shape=(64, 64), title="First 30 Pokemon Images")

import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Load Pokémon images from a directory
def load_images(image_dir, num_images=30):
    image_files = sorted(os.listdir(image_dir))[:num_images]  # Get the first 30 images
    images = []
    titles = [f'Pokemon {i+1}' for i in range(num_images)]  # Generate titles
    return images, titles

# Directory containing the Pokémon images (ensure correct path)
image_dir = "/content/drive/MyDrive/Dataset/orl_faces/Train"  # Replace with your actual image directory
image_height, image_width = 120, 120  # Replace with actual image dimensions (height, width)

# Load the first 30 Pokémon images
images, titles = load_images(image_dir, num_images=30)

# Reshape images if needed (only if they are stored as 1D arrays)
images = [img.reshape(image_height, image_width) if len(img.shape) == 1 else img for img in images]

# Call plot_gallery to visualize the Pokémon images
plot_gallery(images, titles, image_height, image_width, n_row=5, n_col=6)

"""
---

**(c):**

- Perform PCA on the Pokemon dataset to find the first 200 principal components. Visualise the first 200 using ``plot_gallery``.
- Plot the associated eigenvalues with the kth principle component. How can you interpret these?
- Q&A: What do you notice about the first few principal components? What are they detecting?
---



"""

def display_image_gallery(images, labels, height, width, rows=2, cols=6, gallery_title="Image Gallery"):

    assert len(images) >= rows * cols, "Not enough images for the gallery."
    assert len(labels) >= rows * cols, "Not enough labels for the images."

    plt.figure(figsize=(1.8 * cols, 2.4 * rows))
    plt.suptitle(gallery_title, size=16)

    for idx in range(rows * cols):
        plt.subplot(rows, cols, idx + 1)
        plt.imshow(images[idx].reshape((height, width)), cmap='gray')
        plt.title(labels[idx], size=10)
        plt.xticks([])
        plt.yticks([])

    plt.show()

def perform_pca(data, components):

    mean_image = np.mean(data, axis=0)
    centered_data = data - mean_image
    covariance_matrix = np.cov(centered_data.T)

    eigenvalues, eigenvectors = np.linalg.eig(covariance_matrix)
    sorted_indices = np.argsort(eigenvalues)[::-1]

    eigenvectors = eigenvectors[:, sorted_indices]
    eigenvalues = eigenvalues[sorted_indices]

    eigenvectors = np.real(eigenvectors[:, :components])
    projections = np.dot(centered_data, eigenvectors)

    return projections, eigenvectors, eigenvalues

# Set the number of principal components
num_components = 200

# Perform PCA and retrieve the projections, eigenvectors, and eigenvalues
projections_200, principal_components, pca_eigenvalues = perform_pca(pokemon_data, num_components)

# Create titles for the principal components
pc_titles = [f"PC {i+1}" for i in range(num_components)]

# Display the first 200 principal components in a gallery format
display_image_gallery(principal_components.T, pc_titles, height=64, width=64, rows=10, cols=20, gallery_title="Top 200 Principal Components")

# Plot the associated eigenvalues with the kth principle component. How can you interpret these?


plt.figure(figsize=(8, 6))
plt.plot(eigenvalues[:num_components], marker='o', linestyle='-', color='b')
plt.title('Eigenvalues Corresponding to Principal Components')
plt.xlabel('Principal Component Index (k)')
plt.ylabel('Eigenvalue')
plt.grid(True)
plt.show()

"""The steep decline in eigenvalues shows that the first few principal components capture most of the dataset's key information, allowing for dimensionality reduction with minimal loss. Early components focus on broad features like shapes and patterns, while later ones capture finer details.

---

**(d):** Reconstructing images using PCA. Plot the reconstructions of the first 30 images using 200 principal components, and using the first 15 principal components. Compare and comment on how good are these reconstructions.

---
"""

num_components = 200  # Number of principal components for PCA

# Perform PCA with 200 components
projections_200, eigenvectors_200, _ = pca(pokemon_data, num_components)


reconstructed_pokemon_200 = np.dot(projections_200[:, :num_components], eigenvectors_200.T[:num_components, :])

# Set up a figure with 2 rows and 30 columns for displaying images
fig, axes = plt.subplots(2, 30, figsize=(30, 5))

for i in range(30):
    # Display the original images in the first row
    axes[0, i].imshow(pokemon_data[i].reshape(64, 64), cmap='gray')
    axes[0, i].axis('off')  # Turn off axis for clean display
    if i == 0:
        axes[0, i].set_title('Original Images')  # Title for original images

    # Display the reconstructed images in the second row (200 components)
    reconstructed_image = reconstructed_pokemon_200[i].reshape(64, 64)
    axes[1, i].imshow(reconstructed_image, cmap='gray')
    axes[1, i].axis('off')  # Turn off axis for clean display
    if i == 0:
        axes[1, i].set_title('Reconstructed Images (200 PCs)')  # Title for reconstructed images


plt.tight_layout()
plt.show()

n_components = 15

# Perform PCA with 15 components
projections_15, eigenvectors_15, _ = pca(pokemon_data, n_components)

# Reconstruct images using the 15 principal components
reconstructed_pokemon_15 = np.dot(projections_15[:, :n_components], eigenvectors_15.T[:n_components, :])

# Plot original and reconstructed images side by side
fig, axes = plt.subplots(2, 30, figsize=(30, 5))

for i in range(30):

    axes[0, i].imshow(pokemon_data[i].reshape(64, 64), cmap='gray')
    axes[0, i].axis('off')
    if i == 0:
        axes[0, i].set_title('Original Images')

    # Plot reconstructed images (15 components)
    reconstructed_image = reconstructed_pokemon_15[i].reshape(64, 64)
    axes[1, i].imshow(reconstructed_image, cmap='gray')
    axes[1, i].axis('off')
    if i == 0:
        axes[1, i].set_title('Reconstructed Images (15 PCs)')


plt.tight_layout()
plt.show()

"""At first, we used 200 principal components to reconstruct the images, which resulted in clearer and more detailed results. When we reduced the number of components to 15, the images became blurrier and less distinct. This demonstrates the importance of selecting the right number of components. Too few components lead to a loss of detail, while using too many can reduce the benefits of data compression. It's essential to find a balance between reducing dimensionality and preserving image quality for optimal reconstruction.Comment and compare

---

**(e) Class specificity:** Compose the $s_1$ test example from Eigen Pokemons. With Eigen Pokemons base k=10, 30, 100, 200.

Observe and comment on the performance of this operation and explain why this happened?

Hint: since the dimension of human face (112x92) is different from pokemon image (64x64). Please first crop the human face image to (64x64) from the center of the image.

---
"""

def crop_to_center(image, new_size=(64, 64)):

    original_height, original_width = image.shape
    new_height, new_width = new_size

    first_y = (original_height - new_height)
    first_x = (original_width - new_width)

    return image[first_y:first_y + new_height, first_x:first_x + new_width]

face_image_path = '/content/drive/MyDrive/Dataset/Dataset/orlfaces/Test/s1/10.pgm' #file path
face_image = Image.open(face_image_path).convert('L')
face_image = np.array(face_image)

# Crop to to 64x64
cropped_face = crop_to_center(face_image, new_size=(64, 64))

# Ploting human face and the processed face
plt.figure(figsize=(5, 5))
plt.subplot(2, 3, 1)
plt.imshow(face_image, cmap='gray')
plt.title("Human Face (112x92)")
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(cropped_face, cmap='gray')
plt.title("Processed Human Face (64x64)")
plt.axis('off')

plt.show()

# Project the processed face image onto the Pokemon Eigenbasis
def reconstruct_from_pokemon_basis(cropped_face, eigenvectors, mean_pokemon, k):

    centered_face = cropped_face.flatten() - mean_pokemon
    projection = np.dot(centered_face, eigenvectors[:, :k])
    reconstructed_face = np.dot(projection, eigenvectors[:, :k].T) + mean_pokemon
    return reconstructed_face

mean_pokemon = np.mean(pokemon_data, axis=0)

k_values = [10, 30, 100, 200]

fig, axes = plt.subplots(1, len(k_values) + 1, figsize=(15, 5))
axes[0].imshow(cropped_face, cmap='gray')
axes[0].set_title("Processed Human Face (64x64)")
axes[0].axis('off')

for i, k in enumerate(k_values):
    reconstructed_face = reconstruct_from_pokemon_basis(cropped_face, eigenvectors, mean_pokemon, k)
    axes[i + 1].imshow(reconstructed_face.reshape(64, 64), cmap='gray')
    axes[i + 1].set_title(f"Reconstructed (k={k})")
    axes[i + 1].axis('off')

plt.tight_layout()
plt.show()

"""**You are ready to submit in Canvas!**

4 easy steps to submit your lab:

1.   Go to "File" - Download both ".ipynb" and ".py"
2.   Click on "Share" option on top right - Click on "copy link" option. Make sure your permission is set to "Anyone on the internet with this link can view"
3.   Upload both ".ipynb" and ".py" file obtained from Step (1) with your 'results' folder to Canvas. If it is too big, zip it before uploading.
4.   In the text comments on Canvas, paste the link obtained from Step (3).

That's it!

In short, we want to have one link, one .ipynb, one .py file and one 'Lab3_yourJHID.zip' containing all the required outputs.

Please suffix your colab file and the zip file with your _jhID, eg: Lab3_myjhID12

"""